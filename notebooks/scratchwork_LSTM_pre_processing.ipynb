{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be47de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from datetime import date\n",
    "from statistics import mode\n",
    "import codebase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fdc9ec",
   "metadata": {},
   "source": [
    "- below Hoover Dam: 4152103\n",
    "- Lee's Ferry: 4152450\n",
    "- US-Mexico border: 4152050\n",
    "- upstream of Lake Powell (San Juan River trib): 4152600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c2359488",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define experimental set-up\n",
    "\n",
    "# grdc stored as floats in the downlaod jsons\n",
    "grdc_id = 4152050\n",
    "grdc_sub_ids = [4152103,4152600] ## MUST BE ORDERED DOWNSTREAM (first) TO UPSTREAM (last)\n",
    "dam_name = 'glen canyon'\n",
    "start_year = 2018\n",
    "stop_year_ex = 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5d728442",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Other variables and filepaths\n",
    "grdc_dir = \"/global/scratch/users/ann_scheliga/aux_dam_datasets/GRDC_CRB/\"\n",
    "met_dir = \"/global/scratch/users/ann_scheliga/era5_data/\"\n",
    "res_dir = \"/global/scratch/users/ann_scheliga/CYGNSS_daily/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c4a8ffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For debugging\n",
    "def check_data_format(df):\n",
    "    print(df.head(2))\n",
    "    print(df.tail(2))\n",
    "    print('structure type:',type(df))\n",
    "    print('index type:',type(df.index))\n",
    "    print('first index:',df.index[0])\n",
    "    print('Inferred frequency:',df.index.inferred_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b1cdffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output dataframe\n",
    "full_time = pd.date_range(start=date(start_year,1,1), end=date(stop_year_ex,1,1),freq='D')\n",
    "output_df = pd.DataFrame(index = full_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f7096666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-01    380.752060\n",
      "2019-01-02    362.621009\n",
      "Name: Area km2, dtype: float64\n",
      "2023-12-31    298.685200\n",
      "2024-01-01    293.913871\n",
      "Name: Area km2, dtype: float64\n",
      "structure type: <class 'pandas.core.series.Series'>\n",
      "index type: <class 'pandas.core.indexes.datetimes.DatetimeIndex'>\n",
      "first index: 2019-01-01 00:00:00\n",
      "Inferred frequency: D\n"
     ]
    }
   ],
   "source": [
    "## import sw_area\n",
    "sw_area = codebase.load_data.load_daily_reservoir_CYGNSS_area(\n",
    "    dam_name, filepath=res_dir\n",
    ")\n",
    "\n",
    "output_df['SW_area'] = sw_area\n",
    "check_data_format(sw_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f37cd047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-01    0\n",
      "2018-01-02    0\n",
      "Freq: D, Name: SW_flag, dtype: int64\n",
      "2023-12-31    1\n",
      "2024-01-01    1\n",
      "Freq: D, Name: SW_flag, dtype: int64\n",
      "structure type: <class 'pandas.core.series.Series'>\n",
      "index type: <class 'pandas.core.indexes.datetimes.DatetimeIndex'>\n",
      "first index: 2018-01-01 00:00:00\n",
      "Inferred frequency: D\n"
     ]
    }
   ],
   "source": [
    "## Calculate SW_flag\n",
    "output_df['SW_flag'] = 0\n",
    "# where SW_area has a value, SW_flag is true\n",
    "output_df.loc[~output_df['SW_area'].isna(),'SW_flag'] = 1 \n",
    "\n",
    "check_data_format(output_df['SW_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "83b3bcf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Q m3s\n",
      "Date              \n",
      "2018-01-01  25.542\n",
      "2018-01-02  28.600\n",
      "             Q m3s\n",
      "Date              \n",
      "2023-12-30  18.548\n",
      "2023-12-31  19.029\n",
      "structure type: <class 'pandas.core.frame.DataFrame'>\n",
      "index type: <class 'pandas.core.indexes.datetimes.DatetimeIndex'>\n",
      "first index: 2018-01-01 00:00:00\n",
      "Inferred frequency: D\n"
     ]
    }
   ],
   "source": [
    "## import GRDC\n",
    "watershed_gpd, grdc_Q = codebase.load_data.load_GRDC_station_data_by_ID(\n",
    "    grdc_id,\n",
    "    filepath=grdc_dir,\n",
    "    timeseries_dict={\"start_year\": start_year, \"stop_year\": stop_year_ex},\n",
    ")\n",
    "\n",
    "output_df['Q'] = grdc_Q\n",
    "check_data_format(grdc_Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a785af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given that sub-basins exist\n",
    "subbasins_GRDC = list(map(\n",
    "    lambda id: codebase.load_data.load_GRDC_station_data_by_ID(\n",
    "        id,filepath=grdc_dir,\n",
    "        timeseries_dict={\"start_year\": start_year, \"stop_year\": stop_year_ex}\n",
    "        ),\n",
    "    grdc_sub_ids))\n",
    "# subbasin_zipped = dict(zip(grdc_sub_ids,subbasins_GRDC))\n",
    "\n",
    "# drop flow timeseries tuple from list, leave just the geoDataFrame(s)\n",
    "subbasin_shps = [output[0] for output in subbasins_GRDC]\n",
    "def create_XOR_subasins(list_of_shps,base_gpd):\n",
    "    processed_shps = base_gpd.iloc[:,-1]\n",
    "    processed_shps.index = ['_ex0']\n",
    "    processed_shps.index.rename('relative_order',inplace=True)\n",
    "\n",
    "    for idx, shp in enumerate(list_of_shps):\n",
    "        shp_to_diff = shp.iloc[0,-1]\n",
    "        processed_shps = processed_shps.difference(shp_to_diff)\n",
    "        processed_shps.loc['_ex'+str(idx+1)] = shp_to_diff\n",
    "    return processed_shps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "11a30763",
   "metadata": {},
   "outputs": [],
   "source": [
    "XOR_gpd = create_XOR_subasins(subbasin_shps,watershed_gpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee45fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Can't get mode function to work easily.\n",
    "# Tried scipy and statistics modules\n",
    "# type_precip_test = codebase.area_subsets.era5_shape_subset_and_concat_from_file_pattern(\n",
    "#     filepath = met_dir,\n",
    "#     input_pattern = r'daily_precip_type',\n",
    "#     subset_gpd = watershed_gpd,\n",
    "#     concat_dict = concat_dict,\n",
    "#     agg_function = mode\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f16d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_era5_met_data_by_shp(input_gpd):\n",
    "    \n",
    "    concat_dict = {\"dim\": \"valid_time\"}\n",
    "\n",
    "    __ , tempK_1dim = codebase.area_subsets.era5_shape_subset_and_concat_from_file_pattern(\n",
    "        filepath = met_dir,\n",
    "        input_pattern = r'daily_tempK',\n",
    "        subset_gpd = input_gpd,\n",
    "        concat_dict = concat_dict,\n",
    "        agg_function = np.nanmean\n",
    "    )\n",
    "    tempK_1dim.rename('tempK',inplace=True)\n",
    "\n",
    "    __ , precip_1dim = codebase.area_subsets.era5_shape_subset_and_concat_from_file_pattern(\n",
    "        filepath = met_dir,\n",
    "        input_pattern = r'daily_tot_precip',\n",
    "        subset_gpd = input_gpd,\n",
    "        concat_dict = concat_dict,\n",
    "        agg_function = np.nansum\n",
    "    )\n",
    "    precip_1dim.rename('precipm',inplace=True)\n",
    "    met_df = pd.concat([tempK_1dim, precip_1dim],axis=1)\n",
    "    return met_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe46849",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_extension = '_tot0'\n",
    "met_df = add_era5_met_data_by_shp(watershed_gpd).add_suffix(sub_extension)\n",
    "output_df = output_df.join(met_df, how='left')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rioxarray_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
