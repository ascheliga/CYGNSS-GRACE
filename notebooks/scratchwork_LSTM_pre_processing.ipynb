{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be47de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import geopandas as gpd\n",
    "from datetime import date\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import codebase\n",
    "from codebase import ml_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fdc9ec",
   "metadata": {},
   "source": [
    "- US-Mexico border: 4152050\n",
    "- below Hoover Dam: 4152103\n",
    "- Lee's Ferry: 4152450\n",
    "- upstream of Lake Powell (San Juan River trib): 4152600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2359488",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define experimental set-up\n",
    "\n",
    "# grdc stored as floats in the downlaod jsons\n",
    "grdc_id = 1834101\n",
    "grdc_sub_ids = []#[4152450,4152600] ## MUST BE ORDERED DOWNSTREAM (first) TO UPSTREAM (last)\n",
    "dam_name = 'kainji'\n",
    "start_year = 2010\n",
    "stop_year_ex = 2024\n",
    "basin_str = 'niger'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d728442",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Other variables and filepaths\n",
    "grdc_dir = \"/global/scratch/users/ann_scheliga/aux_dam_datasets/GRDC_CRB/\"\n",
    "met_dir = \"/global/scratch/users/ann_scheliga/era5_data/\"\n",
    "res_dir = \"/global/scratch/users/ann_scheliga/CYGNSS_daily/time_series/\"\n",
    "basin_data_dir = \"/global/scratch/users/ann_scheliga/basin_forcing_processed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c00c23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = ml_pipeline.LSTM_preprocessing_nh(grdc_id,\n",
    "    grdc_sub_ids,\n",
    "    dam_name = 'glen canyon',\n",
    "    start_year = 2018,\n",
    "    stop_year_ex = 2024,\n",
    "    save_output=False,\n",
    "    basin_str=basin_str,\n",
    "    res_dir=res_dir\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4916ad0",
   "metadata": {},
   "source": [
    "## testing EDA plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77b0887",
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_cols = test_df.columns[test_df.columns.str.contains(\"precip\")]\n",
    "tempK_cols = test_df.columns[test_df.columns.str.contains(\"tempK\")]\n",
    "dewpoint_cols = test_df.columns[test_df.columns.str.contains(\"dew\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30254aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[dewpoint_cols].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d1d19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[tempK_cols].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72ddaaf",
   "metadata": {},
   "source": [
    "## pre-processing step-by-step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4a8ffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For debugging\n",
    "def check_data_format(df):\n",
    "    print(df.head(2))\n",
    "    print(df.tail(2))\n",
    "    print('structure type:',type(df))\n",
    "    print('index type:',type(df.index))\n",
    "    print('first index:',df.index[0])\n",
    "    print('Inferred frequency:',df.index.inferred_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cdffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output dataframe\n",
    "full_time = pd.date_range(start=date(start_year,1,1), end=date(stop_year_ex,1,1),freq='D')\n",
    "output_df = pd.DataFrame(index = full_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7096666",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import sw_area\n",
    "sw_area = codebase.load_data.load_daily_reservoir_CYGNSS_area(\n",
    "    dam_name, filepath=res_dir\n",
    ")\n",
    "output_df['SW_area'] = sw_area\n",
    "output_df['SW_area'].fillna(output_df['SW_area'].mean(),inplace=True)\n",
    "\n",
    "check_data_format(output_df['SW_area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37cd047",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate SW_flag\n",
    "output_df['SW_flag'] = 0\n",
    "# where SW_area has a value, SW_flag is true\n",
    "output_df.loc[~output_df['SW_area'].isna(),'SW_flag'] = 1 \n",
    "\n",
    "check_data_format(output_df['SW_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371dac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "grdc_Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b3bcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import GRDC\n",
    "watershed_gpd, grdc_Q = codebase.load_data.load_GRDC_station_data_by_ID(\n",
    "    grdc_id,\n",
    "    filepath=grdc_dir,\n",
    "    timeseries_dict={\"start_year\": start_year, \"stop_year\": stop_year_ex},\n",
    "    basin_str='niger'\n",
    ")\n",
    "\n",
    "output_df['Q'] = grdc_Q\n",
    "check_data_format(grdc_Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a785af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given that sub-basins exist\n",
    "subbasins_GRDC = list(map(\n",
    "    lambda id: codebase.load_data.load_GRDC_station_data_by_ID(\n",
    "        id,filepath=grdc_dir,\n",
    "        timeseries_dict={\"start_year\": start_year, \"stop_year\": stop_year_ex}\n",
    "        ),\n",
    "    grdc_sub_ids))\n",
    "# subbasin_zipped = dict(zip(grdc_sub_ids,subbasins_GRDC))\n",
    "\n",
    "# drop flow timeseries tuple from list, leave just the geoDataFrame(s)\n",
    "subbasin_shps = [output[0] for output in subbasins_GRDC]\n",
    "def create_XOR_subasins(list_of_shps,base_gpd):\n",
    "    processed_shps = base_gpd.iloc[:,-1]\n",
    "    processed_shps.index = ['_ex0']\n",
    "    processed_shps.index.rename('relative_order',inplace=True)\n",
    "\n",
    "    for idx, shp in enumerate(list_of_shps):\n",
    "        shp_to_diff = shp.iloc[0,-1]\n",
    "        processed_shps = processed_shps.difference(shp_to_diff)\n",
    "        processed_shps.loc['_ex'+str(idx+1)] = shp_to_diff\n",
    "    \n",
    "    # Using the .difference() method wth a shapely shape removes the crs\n",
    "    processed_shps.set_crs(base_gpd.crs,inplace=True)\n",
    "\n",
    "    return processed_shps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a30763",
   "metadata": {},
   "outputs": [],
   "source": [
    "XOR_geoms = create_XOR_subasins(subbasin_shps,watershed_gpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4936b7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check, not essentia\n",
    "print(XOR_geoms.index)\n",
    "XOR_geoms.boundary.plot(cmap='viridis')\n",
    "XOR_geoms[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee45fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Can't get mode function to work easily.\n",
    "# Tried scipy and statistics modules\n",
    "# type_precip_test = codebase.area_subsets.era5_shape_subset_and_concat_from_file_pattern(\n",
    "#     filepath = met_dir,\n",
    "#     input_pattern = r'daily_precip_type',\n",
    "#     subset_gpd = watershed_gpd,\n",
    "#     concat_dict = concat_dict,\n",
    "#     agg_function = mode\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05973d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets_gpd = pd.concat([watershed_gpd,*subbasin_shps])\n",
    "subsets_geoms = subsets_gpd['geometry'].reset_index(drop=True).add_prefix('_tot')\n",
    "subsets_geoms[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8277f1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_shps = pd.concat([subsets_geoms,XOR_geoms]).rename('geometry')#.reset_index()\n",
    "all_shps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f16d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_era5_met_data_by_shp(input_gpd,met_dir,col_suffix = \"\",start_year=-1,stop_year_ex=-1):\n",
    "    \"\"\"\n",
    "    Load areal aggregated temp and precip based on provided gpd.\n",
    "\n",
    "    Long Description\n",
    "    ----------------\n",
    "    Uses `area_subsets.era5_shape_subset_and_concat_from_file_pattern` for each variable.\n",
    "    Searches for all instances of a substring (ex: 'daily_tempK'),\n",
    "    and concatenates all found files according to hard-coded concat_dict dimensions.\n",
    "    For precipitation, aggregates using np.nansum\n",
    "    For temperature, aggregates using np.nanmean.\n",
    "    start and stop year not used, but included in case useful in future edits.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    input_gpd : geopandas.GeoDataFrame\n",
    "        geometry to subset data\n",
    "    col_suffix : str\n",
    "        default = \"\" (empty)\n",
    "        added to column names in final output dataframe\n",
    "        useful when using this function multiple times\n",
    "    start_year, stop_year_ex : int\n",
    "        default = -1\n",
    "        not used, passed in case future edits need the bounds\n",
    "        for pattern parsing or filtering.\n",
    "    \"\"\"\n",
    "    \n",
    "    concat_dict = {\"dim\": \"valid_time\"}\n",
    "\n",
    "    __ , tempK_1dim = codebase.area_subsets.era5_shape_subset_and_concat_from_file_pattern(\n",
    "        filepath = met_dir,\n",
    "        input_pattern = r'daily_tempK',\n",
    "        subset_gpd = input_gpd,\n",
    "        concat_dict = concat_dict,\n",
    "        agg_function = np.nanmean\n",
    "    )\n",
    "    tempK_1dim.rename('tempK',inplace=True)\n",
    "\n",
    "    __ , precip_1dim = codebase.area_subsets.era5_shape_subset_and_concat_from_file_pattern(\n",
    "        filepath = met_dir,\n",
    "        input_pattern = r'daily_tot_precip',\n",
    "        subset_gpd = input_gpd,\n",
    "        concat_dict = concat_dict,\n",
    "        agg_function = np.nansum\n",
    "    )\n",
    "    precip_1dim.rename('precipm',inplace=True)\n",
    "    met_df = pd.concat([tempK_1dim, precip_1dim],axis=1).add_suffix(col_suffix)\n",
    "    return met_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b0eb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "met_list = list(map(lambda idx: add_era5_met_data_by_shp(all_shps.loc[[idx]],met_dir=met_dir,col_suffix=idx),all_shps.index[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23bdefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "met_df = pd.concat(met_list,axis=1)\n",
    "output_df = output_df.join(met_df, how='left')\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7602f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.interpolate(\n",
    "        method=\"linear\", axis=0, inplace=True  , limit=7\n",
    "    )  # interpolate missing interior values\n",
    "# output_df.bfill(inplace=True, limit=2)  # backfill missing first precip value\n",
    "output_df.index.name = 'date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d11434",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5b1ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict= {grdc_id:output_df}\n",
    "filename = str(grdc_id)+'.pkl'\n",
    "pickle.dump(output_dict, open(basin_data_dir+filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eb5caa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8862dccb",
   "metadata": {},
   "source": [
    "## Manual data processing\n",
    "Replaced the SW_area nan values with the mean. Did not rerun the full pre-processing script. Manually overwrote. Pre-processing script contains the updated .fillna() fix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e700c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_pkls = [fn for fn in os.listdir(basin_data_dir) if '.pkl' in fn]\n",
    "# all_pkls.sort()\n",
    "def replace_SW_nan_with_mean(fn):\n",
    "    test_read = pickle.load(open(basin_data_dir+fn, 'rb'))\n",
    "    grdc_id = list(test_read.keys())[0]\n",
    "    print('GRDC ID:',grdc_id)\n",
    "    output_df = test_read[grdc_id]\n",
    "    sw_mean = output_df[\"SW_area\"].mean()\n",
    "    print('SW_mean:',sw_mean)\n",
    "    output_df[\"SW_area\"].fillna(sw_mean, inplace=True)\n",
    "    check_data_format(output_df)\n",
    "\n",
    "    output_dict= {grdc_id:output_df}\n",
    "    pickle.dump(output_dict, open(basin_data_dir+fn, 'wb'))\n",
    "# replace_SW_nan_with_mean(all_pkls[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0d36f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRDC ID: 5608096\n",
      "SW_mean: 1109.5844779328816\n",
      "                SW_area  SW_flag       Q  max_tempK_tot0  min_tempK_tot0  \\\n",
      "date                                                                       \n",
      "2000-01-01  1109.584478        0  53.225      300.054321      294.764191   \n",
      "2000-01-02  1109.584478        0  52.407      298.432037      294.155884   \n",
      "\n",
      "            precipm_tot0  dewpointK_tot0  max_tempK_tot1  min_tempK_tot1  \\\n",
      "date                                                                       \n",
      "2000-01-01      0.128849      293.081573      300.573181      294.206329   \n",
      "2000-01-02      0.450547      292.195190      297.472382      293.030182   \n",
      "\n",
      "            precipm_tot1  dewpointK_tot1  max_tempK_ex0  min_tempK_ex0  \\\n",
      "date                                                                     \n",
      "2000-01-01      0.031355      292.013092     299.755280     294.996216   \n",
      "2000-01-02      0.172825      291.009125     299.237671     294.684052   \n",
      "\n",
      "            precipm_ex0  dewpointK_ex0  max_tempK_ex1  min_tempK_ex1  \\\n",
      "date                                                                   \n",
      "2000-01-01     0.095658     293.402710     300.573181     294.206329   \n",
      "2000-01-02     0.261053     292.537842     297.472382     293.030182   \n",
      "\n",
      "            precipm_ex1  dewpointK_ex1  \n",
      "date                                    \n",
      "2000-01-01     0.031355     292.013092  \n",
      "2000-01-02     0.172825     291.009125  \n",
      "                SW_area  SW_flag       Q  max_tempK_tot0  min_tempK_tot0  \\\n",
      "date                                                                       \n",
      "2023-12-31  1272.968333        1  56.045      313.628845      302.334198   \n",
      "2024-01-01  1269.209569        1  56.045      313.628845      302.334198   \n",
      "\n",
      "            precipm_tot0  dewpointK_tot0  max_tempK_tot1  min_tempK_tot1  \\\n",
      "date                                                                       \n",
      "2023-12-31      0.003628      292.578491      314.416931      302.923401   \n",
      "2024-01-01      0.003628      292.578491      314.416931      302.923401   \n",
      "\n",
      "            precipm_tot1  dewpointK_tot1  max_tempK_ex0  min_tempK_ex0  \\\n",
      "date                                                                     \n",
      "2023-12-31      0.001264      290.434631     313.268188      302.05896   \n",
      "2024-01-01      0.001264      290.434631     313.268188      302.05896   \n",
      "\n",
      "            precipm_ex0  dewpointK_ex0  max_tempK_ex1  min_tempK_ex1  \\\n",
      "date                                                                   \n",
      "2023-12-31     0.001579     293.521973     314.416931     302.923401   \n",
      "2024-01-01     0.001579     293.521973     314.416931     302.923401   \n",
      "\n",
      "            precipm_ex1  dewpointK_ex1  \n",
      "date                                    \n",
      "2023-12-31     0.001264     290.434631  \n",
      "2024-01-01     0.001264     290.434631  \n",
      "structure type: <class 'pandas.core.frame.DataFrame'>\n",
      "index type: <class 'pandas.core.indexes.datetimes.DatetimeIndex'>\n",
      "first index: 2000-01-01 00:00:00\n",
      "Inferred frequency: D\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8784901a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rioxarray_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
